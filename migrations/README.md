# Database Migration System

This directory contains the Alembic migration system for managing database schema changes.

## Overview

This project uses **Alembic** with **SQLAlchemy Core** (not ORM) to manage database migrations. The system is integrated with the Flask application factory pattern.

### Key Features

- ✅ **SQLAlchemy Core Support**: Works with Table objects, not ORM models
- ✅ **Flask Integration**: Reads database config from Flask app settings
- ✅ **PostgreSQL + PostGIS**: Full support for spatial data types
- ✅ **Type-Safe**: Detects column type and default value changes
- ✅ **Transactional**: PostgreSQL's transactional DDL ensures atomic migrations

## Directory Structure

```
migrations/
├── README.md                    # This file
├── env.py                       # Alembic environment configuration
├── script.py.mako               # Template for new migrations
└── versions/                    # Migration scripts
    ├── 0001_initial_schema.py   # Initial database schema
    └── 0002_add_project_archiving.py  # Phase 10: Archiving system
```

## Requirements

### Environment Variables

The migration system requires the following environment variables to be set in your `.env` file:

```bash
# PostgreSQL Connection (choose one method)

# Method 1: Individual components
PGHOST=your-database-host
PGPORT=5432
PGDATABASE=your-database-name
PGUSER=your-username
PGPASSWORD=your-password

# Method 2: Direct URI
SQLALCHEMY_DATABASE_URI=postgresql://user:password@host:port/database
```

### Dependencies

All required packages are already in `requirements.txt`:
- `alembic==1.13.1`
- `Flask-Migrate==4.0.5`
- `SQLAlchemy==2.0.23`
- `GeoAlchemy2==0.14.2`
- `psycopg2-binary==2.9.11`

## Usage

### Using the migrate.py CLI

The `migrate.py` script provides a user-friendly interface to Alembic:

```bash
# Check current database revision
python migrate.py db current

# View migration history
python migrate.py db history

# Apply all pending migrations
python migrate.py db upgrade

# Rollback one migration
python migrate.py db downgrade

# Generate a new migration (autogenerate)
python migrate.py db migrate --message "add user table"

# Create an empty migration (manual)
python migrate.py db revision --message "custom migration"

# Show details of a specific migration
python migrate.py db show 0001

# Generate SQL without executing
python migrate.py db upgrade --sql
```

### Using Alembic Directly

You can also use Alembic commands directly:

```bash
# Check current revision
alembic current

# Show migration history
alembic history --verbose

# Upgrade to latest
alembic upgrade head

# Upgrade to specific revision
alembic upgrade 0001

# Downgrade one revision
alembic downgrade -1

# Downgrade to specific revision
alembic downgrade 0001

# Generate SQL for upgrade
alembic upgrade head --sql
```

## Migration Workflow

### Initial Setup (New Database)

If you're setting up a fresh database:

```bash
# 1. Ensure your .env file has correct database credentials
# 2. Apply all migrations
python migrate.py db upgrade

# This will create all tables defined in migrations/versions/
```

### Existing Database Setup

If you already have a database with the schema:

```bash
# Mark the current schema as migrated without running migrations
# This tells Alembic "these migrations are already applied"

# If your database has the initial schema:
alembic stamp 0001

# If your database has archiving columns too:
alembic stamp 0002
```

### Creating New Migrations

#### Option 1: Autogenerate (Recommended)

Alembic can compare your SQLAlchemy models with the database and generate migrations:

```bash
# 1. Update your models in app/data_models.py
# 2. Generate migration
python migrate.py db migrate --message "add email to users"

# 3. Review the generated file in migrations/versions/
# 4. Edit if needed (autogenerate isn't perfect)
# 5. Apply the migration
python migrate.py db upgrade
```

**Important**: Always review autogenerated migrations! They may miss:
- Custom types (like PostGIS geometry types)
- Complex constraints
- Data migrations
- Index changes on expressions

#### Option 2: Manual Migration

For complex changes, create a blank migration and write it manually:

```bash
# 1. Create empty migration
python migrate.py db revision --message "complex data migration"

# 2. Edit the generated file in migrations/versions/
# 3. Write upgrade() and downgrade() functions
# 4. Test and apply
python migrate.py db upgrade
```

### Testing Migrations

Always test migrations before production:

```bash
# 1. Create a database backup
pg_dump your_database > backup.sql

# 2. Apply migration
python migrate.py db upgrade

# 3. Test the application

# 4. If issues occur, rollback
python migrate.py db downgrade

# 5. Fix the migration and try again
```

## Migration Files

### 0001_initial_schema.py

Creates the complete initial database schema:

- **Tables**: projects, survey_points, easements, block_definitions, attribute_codes, entity_relationships, horizontal_alignments, drawing_hatches, audit_log, ai_query_cache
- **Indexes**: All required indexes for performance
- **Extensions**: PostGIS, uuid-ossp
- **Constraints**: Foreign keys, primary keys, unique constraints

**Note**: Does NOT include Phase 10 archiving columns.

### 0002_add_project_archiving.py

Implements Phase 10: Two-Stage Project Archiving & Deletion System

Adds to `projects` table:
- `is_archived` (Boolean): Soft delete flag
- `archived_at` (DateTime): Archive timestamp
- `archived_by` (UUID): User who archived the project
- Index on `is_archived` for query performance

**Safety**: Safe to run on production - adds nullable columns with defaults.

## Best Practices

### DO:

✅ **Always backup** before running migrations on production
✅ **Test migrations** on a staging database first
✅ **Review autogenerated** migrations carefully
✅ **Write both upgrade and downgrade** functions
✅ **Use transactions** (PostgreSQL supports transactional DDL)
✅ **Add comments** to explain complex migrations
✅ **Keep migrations small** and focused

### DON'T:

❌ **Don't edit applied migrations** - create a new one instead
❌ **Don't delete migrations** from the versions/ directory
❌ **Don't skip migrations** - apply them in order
❌ **Don't trust autogenerate** 100% - always review
❌ **Don't run migrations** without a backup

## Troubleshooting

### "Database not found" or Connection Errors

Check your `.env` file has correct credentials:

```bash
# Verify environment variables are loaded
python -c "from app import create_app; app = create_app(); print(app.config['SQLALCHEMY_DATABASE_URI'])"
```

### "Target database is not up to date"

This means there are unapplied migrations:

```bash
# Check what's pending
alembic current
alembic history

# Apply pending migrations
python migrate.py db upgrade
```

### "Can't locate revision identified by 'XXXX'"

The alembic_version table is out of sync:

```bash
# Check what Alembic thinks is current
alembic current

# If incorrect, manually stamp the correct version
alembic stamp head  # or specific revision like 'alembic stamp 0002'
```

### Migration Conflicts

If you have multiple branches with migrations:

```bash
# View heads
alembic heads

# Merge branches (creates a merge migration)
alembic merge -m "merge branches" head1 head2
```

## Production Deployment

### Safe Production Migration Workflow

```bash
# 1. Backup the database
pg_dump production_db > backup_$(date +%Y%m%d_%H%M%S).sql

# 2. Check current state
python migrate.py db current

# 3. Review pending migrations
python migrate.py db history

# 4. Generate SQL to review (don't execute yet)
python migrate.py db upgrade --sql > migration.sql

# 5. Review the SQL
cat migration.sql

# 6. Apply in a transaction (PostgreSQL)
python migrate.py db upgrade

# 7. Verify application works
# 8. If issues: rollback
python migrate.py db downgrade
```

### Zero-Downtime Migrations

For large tables, use these strategies:

1. **Add columns as nullable first**, populate data, then make NOT NULL
2. **Create indexes CONCURRENTLY** (requires raw SQL in migration)
3. **Use batched updates** for data migrations
4. **Split migrations** into multiple smaller steps

Example:

```python
# migrations/versions/XXXX_add_email_part1.py
def upgrade():
    # Step 1: Add nullable column
    op.add_column('users', sa.Column('email', sa.String(255), nullable=True))

# migrations/versions/XXXX_add_email_part2.py
def upgrade():
    # Step 2: Populate data (in batches if large table)
    # Step 3: Add NOT NULL constraint
    op.alter_column('users', 'email', nullable=False)
```

## Integration with CI/CD

### GitHub Actions Example

```yaml
# .github/workflows/migrate.yml
name: Database Migration

on:
  push:
    branches: [main]

jobs:
  migrate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run migrations
        env:
          SQLALCHEMY_DATABASE_URI: ${{ secrets.DATABASE_URL }}
        run: python migrate.py db upgrade
```

## Additional Resources

- [Alembic Documentation](https://alembic.sqlalchemy.org/)
- [SQLAlchemy Core Tutorial](https://docs.sqlalchemy.org/en/20/core/tutorial.html)
- [PostgreSQL Transactional DDL](https://www.postgresql.org/docs/current/sql-begin.html)
- [GeoAlchemy2 Documentation](https://geoalchemy-2.readthedocs.io/)

## Support

For issues or questions:
1. Check this README
2. Review migration files in `migrations/versions/`
3. Check Alembic logs
4. Consult the Alembic documentation
